{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "Major-Project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "RJ4e75LN4h2G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Place all imports here\n",
        "\n",
        "import math\n",
        "import xml.etree.ElementTree as ET\n",
        "import copy\n",
        "import statistics\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras import backend as BK\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "VzmayDJC4h2M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Place configs here\n",
        "total_resources = 60\n",
        "filename = 'Inspiral_100.xml'\n",
        "K = 100\n",
        "n = 13\n",
        "b = 12\n",
        "\n",
        "RESOURCES = [\n",
        "    {'type': 'm4.large', 'cu': 6.5, 'price': 0.1},\n",
        "    {'type': 'm5.xlarge', 'cu': 16, 'price': 0.192},\n",
        "    {'type': 'm5.2xlarge', 'cu': 31, 'price': 0.192},\n",
        "    {'type': 'm5.4xlarge', 'cu': 60, 'price': 0.768},\n",
        "    {'type': 'm5.12xlarge', 'cu': 173, 'price': 2.304},\n",
        "    {'type': 'm5.24xlarge', 'cu': 345, 'price': 4.608}\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "NtSvqgsR4h2S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class File:\n",
        "    name = ''\n",
        "    size = ''\n",
        "\n",
        "    def __init__(self, name, size):\n",
        "        self.name = name\n",
        "        self.size = size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "0lwh-6pE4h2Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Resource:\n",
        "    id = 0\n",
        "    type = ''\n",
        "    cu = 0.0\n",
        "    price = 0.0\n",
        "\n",
        "    def __init__(self, id, type, cu, price):\n",
        "        self.id = id\n",
        "        self.type = type\n",
        "        self.cu = cu\n",
        "        self.price = price"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "yLWO746c4h2d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Task:\n",
        "    id = ''\n",
        "    runtime = 0.0\n",
        "    input_files = list()\n",
        "    output_files = list()\n",
        "    predecessor_tasks = list()\n",
        "    successor_tasks = list()\n",
        "\n",
        "    def __init__(self, id, runtime):\n",
        "        self.id = id\n",
        "        self.runtime = runtime\n",
        "        self.input_files = list()\n",
        "        self.output_files = list()\n",
        "        self.predecessor_tasks = list()\n",
        "        self.successor_tasks = list()\n",
        "\n",
        "    def add_input_file(self, file):\n",
        "        self.input_files.append(file)\n",
        "\n",
        "    def add_output_file(self, file):\n",
        "        self.output_files.append(file)\n",
        "\n",
        "    def add_predecessor_task(self, task):\n",
        "        self.predecessor_tasks.append(task)\n",
        "\n",
        "    def add_successor_task(self, task):\n",
        "        self.successor_tasks.append(task)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RscctG7d2V9w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class HyperVolume:\n",
        "    \"\"\"\n",
        "    Hypervolume computation based on variant 3 of the algorithm in the paper:\n",
        "    C. M. Fonseca, L. Paquete, and M. Lopez-Ibanez. An improved dimension-sweep\n",
        "    algorithm for the hypervolume indicator. In IEEE Congress on Evolutionary\n",
        "    Computation, pages 1157-1163, Vancouver, Canada, July 2006.\n",
        "\n",
        "    Minimization is implicitly assumed here!\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, referencePoint):\n",
        "        \"\"\"Constructor.\"\"\"\n",
        "        self.referencePoint = referencePoint\n",
        "        self.list = []\n",
        "\n",
        "\n",
        "    def compute(self, front):\n",
        "        \"\"\"Returns the hypervolume that is dominated by a non-dominated front.\n",
        "\n",
        "        Before the HV computation, front and reference point are translated, so\n",
        "        that the reference point is [0, ..., 0].\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        def weaklyDominates(point, other):\n",
        "            for i in range(len(point)):\n",
        "                if point[i] > other[i]:\n",
        "                    return False\n",
        "            return True\n",
        "\n",
        "        relevantPoints = []\n",
        "        referencePoint = self.referencePoint\n",
        "        dimensions = len(referencePoint)\n",
        "        for point in front:\n",
        "            # only consider points that dominate the reference point\n",
        "            if weaklyDominates(point, referencePoint):\n",
        "                relevantPoints.append(point)\n",
        "        if any(referencePoint):\n",
        "            # shift points so that referencePoint == [0, ..., 0]\n",
        "            # this way the reference point doesn't have to be explicitly used\n",
        "            # in the HV computation\n",
        "            for j in range(len(relevantPoints)):\n",
        "                relevantPoints[j] = [relevantPoints[j][i] - referencePoint[i] for i in range(dimensions)]\n",
        "        self.preProcess(relevantPoints)\n",
        "        bounds = [-1.0e308] * dimensions\n",
        "        hyperVolume = self.hvRecursive(dimensions - 1, len(relevantPoints), bounds)\n",
        "        return hyperVolume\n",
        "\n",
        "\n",
        "    def hvRecursive(self, dimIndex, length, bounds):\n",
        "        \"\"\"Recursive call to hypervolume calculation.\n",
        "\n",
        "        In contrast to the paper, the code assumes that the reference point\n",
        "        is [0, ..., 0]. This allows the avoidance of a few operations.\n",
        "\n",
        "        \"\"\"\n",
        "        hvol = 0.0\n",
        "        sentinel = self.list.sentinel\n",
        "        if length == 0:\n",
        "            return hvol\n",
        "        elif dimIndex == 0:\n",
        "            # special case: only one dimension\n",
        "            # why using hypervolume at all?\n",
        "            return -sentinel.next[0].cargo[0]\n",
        "        elif dimIndex == 1:\n",
        "            # special case: two dimensions, end recursion\n",
        "            q = sentinel.next[1]\n",
        "            h = q.cargo[0]\n",
        "            p = q.next[1]\n",
        "            while p is not sentinel:\n",
        "                pCargo = p.cargo\n",
        "                hvol += h * (q.cargo[1] - pCargo[1])\n",
        "                if pCargo[0] < h:\n",
        "                    h = pCargo[0]\n",
        "                q = p\n",
        "                p = q.next[1]\n",
        "            hvol += h * q.cargo[1]\n",
        "            return hvol\n",
        "        else:\n",
        "            remove = self.list.remove\n",
        "            reinsert = self.list.reinsert\n",
        "            hvRecursive = self.hvRecursive\n",
        "            p = sentinel\n",
        "            q = p.prev[dimIndex]\n",
        "            while q.cargo != None:\n",
        "                if q.ignore < dimIndex:\n",
        "                    q.ignore = 0\n",
        "                q = q.prev[dimIndex]\n",
        "            q = p.prev[dimIndex]\n",
        "            while length > 1 and (q.cargo[dimIndex] > bounds[dimIndex] or q.prev[dimIndex].cargo[dimIndex] >= bounds[dimIndex]):\n",
        "                p = q\n",
        "                remove(p, dimIndex, bounds)\n",
        "                q = p.prev[dimIndex]\n",
        "                length -= 1\n",
        "            qArea = q.area\n",
        "            qCargo = q.cargo\n",
        "            qPrevDimIndex = q.prev[dimIndex]\n",
        "            if length > 1:\n",
        "                hvol = qPrevDimIndex.volume[dimIndex] + qPrevDimIndex.area[dimIndex] * (qCargo[dimIndex] - qPrevDimIndex.cargo[dimIndex])\n",
        "            else:\n",
        "                qArea[0] = 1\n",
        "                qArea[1:dimIndex+1] = [qArea[i] * -qCargo[i] for i in range(dimIndex)]\n",
        "            q.volume[dimIndex] = hvol\n",
        "            if q.ignore >= dimIndex:\n",
        "                qArea[dimIndex] = qPrevDimIndex.area[dimIndex]\n",
        "            else:\n",
        "                qArea[dimIndex] = hvRecursive(dimIndex - 1, length, bounds)\n",
        "                if qArea[dimIndex] <= qPrevDimIndex.area[dimIndex]:\n",
        "                    q.ignore = dimIndex\n",
        "            while p is not sentinel:\n",
        "                pCargoDimIndex = p.cargo[dimIndex]\n",
        "                hvol += q.area[dimIndex] * (pCargoDimIndex - q.cargo[dimIndex])\n",
        "                bounds[dimIndex] = pCargoDimIndex\n",
        "                reinsert(p, dimIndex, bounds)\n",
        "                length += 1\n",
        "                q = p\n",
        "                p = p.next[dimIndex]\n",
        "                q.volume[dimIndex] = hvol\n",
        "                if q.ignore >= dimIndex:\n",
        "                    q.area[dimIndex] = q.prev[dimIndex].area[dimIndex]\n",
        "                else:\n",
        "                    q.area[dimIndex] = hvRecursive(dimIndex - 1, length, bounds)\n",
        "                    if q.area[dimIndex] <= q.prev[dimIndex].area[dimIndex]:\n",
        "                        q.ignore = dimIndex\n",
        "            hvol -= q.area[dimIndex] * q.cargo[dimIndex]\n",
        "            return hvol\n",
        "\n",
        "\n",
        "    def preProcess(self, front):\n",
        "        \"\"\"Sets up the list data structure needed for calculation.\"\"\"\n",
        "        dimensions = len(self.referencePoint)\n",
        "        nodeList = MultiList(dimensions)\n",
        "        nodes = [MultiList.Node(dimensions, point) for point in front]\n",
        "        for i in range(dimensions):\n",
        "            self.sortByDimension(nodes, i)\n",
        "            nodeList.extend(nodes, i)\n",
        "        self.list = nodeList\n",
        "\n",
        "\n",
        "    def sortByDimension(self, nodes, i):\n",
        "        \"\"\"Sorts the list of nodes by the i-th value of the contained points.\"\"\"\n",
        "        # build a list of tuples of (point[i], node)\n",
        "        decorated = [(node.cargo[i], node) for node in nodes]\n",
        "        # sort by this value\n",
        "        sorted(decorated, key=lambda n: n[0])\n",
        "        # write back to original list\n",
        "        nodes[:] = [node for (_, node) in decorated]\n",
        "            \n",
        "            \n",
        "            \n",
        "class MultiList: \n",
        "    \"\"\"A special data structure needed by FonsecaHyperVolume. \n",
        "    \n",
        "    It consists of several doubly linked lists that share common nodes. So, \n",
        "    every node has multiple predecessors and successors, one in every list.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    class Node: \n",
        "        \n",
        "        def __init__(self, numberLists, cargo=None): \n",
        "            self.cargo = cargo \n",
        "            self.next  = [None] * numberLists\n",
        "            self.prev = [None] * numberLists\n",
        "            self.ignore = 0\n",
        "            self.area = [0.0] * numberLists\n",
        "            self.volume = [0.0] * numberLists\n",
        "    \n",
        "        def __str__(self): \n",
        "            return str(self.cargo)\n",
        "        \n",
        "        \n",
        "    def __init__(self, numberLists):  \n",
        "        \"\"\"Constructor. \n",
        "        \n",
        "        Builds 'numberLists' doubly linked lists.\n",
        "\n",
        "        \"\"\"\n",
        "        self.numberLists = numberLists\n",
        "        self.sentinel = MultiList.Node(numberLists)\n",
        "        self.sentinel.next = [self.sentinel] * numberLists\n",
        "        self.sentinel.prev = [self.sentinel] * numberLists  \n",
        "        \n",
        "        \n",
        "    def __str__(self):\n",
        "        strings = []\n",
        "        for i in range(self.numberLists):\n",
        "            currentList = []\n",
        "            node = self.sentinel.next[i]\n",
        "            while node != self.sentinel:\n",
        "                currentList.append(str(node))\n",
        "                node = node.next[i]\n",
        "            strings.append(str(currentList))\n",
        "        stringRepr = \"\"\n",
        "        for string in strings:\n",
        "            stringRepr += string + \"\\n\"\n",
        "        return stringRepr\n",
        "    \n",
        "    \n",
        "    def __len__(self):\n",
        "        \"\"\"Returns the number of lists that are included in this MultiList.\"\"\"\n",
        "        return self.numberLists\n",
        "    \n",
        "    \n",
        "    def getLength(self, i):\n",
        "        \"\"\"Returns the length of the i-th list.\"\"\"\n",
        "        length = 0\n",
        "        sentinel = self.sentinel\n",
        "        node = sentinel.next[i]\n",
        "        while node != sentinel:\n",
        "            length += 1\n",
        "            node = node.next[i]\n",
        "        return length\n",
        "            \n",
        "            \n",
        "    def append(self, node, index):\n",
        "        \"\"\"Appends a node to the end of the list at the given index.\"\"\"\n",
        "        lastButOne = self.sentinel.prev[index]\n",
        "        node.next[index] = self.sentinel\n",
        "        node.prev[index] = lastButOne\n",
        "        # set the last element as the new one\n",
        "        self.sentinel.prev[index] = node\n",
        "        lastButOne.next[index] = node\n",
        "        \n",
        "        \n",
        "    def extend(self, nodes, index):\n",
        "        \"\"\"Extends the list at the given index with the nodes.\"\"\"\n",
        "        sentinel = self.sentinel\n",
        "        for node in nodes:\n",
        "            lastButOne = sentinel.prev[index]\n",
        "            node.next[index] = sentinel\n",
        "            node.prev[index] = lastButOne\n",
        "            # set the last element as the new one\n",
        "            sentinel.prev[index] = node\n",
        "            lastButOne.next[index] = node\n",
        "        \n",
        "        \n",
        "    def remove(self, node, index, bounds): \n",
        "        \"\"\"Removes and returns 'node' from all lists in [0, 'index'[.\"\"\"\n",
        "        for i in range(index): \n",
        "            predecessor = node.prev[i]\n",
        "            successor = node.next[i]\n",
        "            predecessor.next[i] = successor\n",
        "            successor.prev[i] = predecessor  \n",
        "            if bounds[i] > node.cargo[i]:\n",
        "                bounds[i] = node.cargo[i]\n",
        "        return node\n",
        "    \n",
        "    \n",
        "    def reinsert(self, node, index, bounds):\n",
        "        \"\"\"\n",
        "        Inserts 'node' at the position it had in all lists in [0, 'index'[\n",
        "        before it was removed. This method assumes that the next and previous \n",
        "        nodes of the node that is reinserted are in the list.\n",
        "\n",
        "        \"\"\"\n",
        "        for i in range(index): \n",
        "            node.prev[i].next[i] = node\n",
        "            node.next[i].prev[i] = node\n",
        "            if bounds[i] > node.cargo[i]:\n",
        "                bounds[i] = node.cargo[i]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "gws2pfPk4h2i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Workflow:\n",
        "    id = 0\n",
        "    workflow = list()\n",
        "    processing_time = dict()\n",
        "    makespan = 0\n",
        "    total_cost = 0\n",
        "    cost = dict()\n",
        "    degree_of_imbalance = 0.0\n",
        "    task_to_resource_dict = dict()\n",
        "    billing_time = dict()\n",
        "    rel_inverse = 1.0\n",
        "    energy = 0.0\n",
        "\n",
        "    def __init__(self):\n",
        "        self.id = 0\n",
        "        self.workflow = list()\n",
        "        self.makespan = 0\n",
        "        self.total_cost = 0\n",
        "        self.processing_time = dict()\n",
        "        self.cost = dict()\n",
        "        self.degree_of_imbalance = 0\n",
        "        self.task_to_resource_dict = dict()\n",
        "        self.billing_time = dict()\n",
        "        self.rel_inverse = 1.0\n",
        "        self.energy = 0.0\n",
        "\n",
        "    def add_to_workflow(self, task, resource):\n",
        "        self.workflow.append((task, resource))\n",
        "        self.task_to_resource_dict[task] = resource\n",
        "        self.billing_time[resource] = 0\n",
        "\n",
        "    def calculate_makespan(self, tasks_dict, resources_dict, dag_dict):\n",
        "        processing_time = dict()\n",
        "        start_time = dict()\n",
        "        finish_time = dict()\n",
        "\n",
        "        for (task, resource) in self.workflow:\n",
        "            processing_time[task] = float(tasks_dict[task].runtime / resources_dict[resource].cu)\n",
        "            max_time = 0\n",
        "            for predecessor in tasks_dict[task].predecessor_tasks:\n",
        "                if self.task_to_resource_dict[predecessor] != resource:\n",
        "                    max_time = max(max_time, dag_dict[predecessor][task]/(1024.0*1024*1024))\n",
        "            processing_time[task] += max_time\n",
        "\n",
        "        for (task, resource) in self.workflow:\n",
        "            if len(tasks_dict[task].predecessor_tasks) == 0:\n",
        "                finish_time[task] = processing_time[task]\n",
        "            else:\n",
        "                finish_time[task] = processing_time[task] + max([finish_time[x] for x in tasks_dict[task].predecessor_tasks])\n",
        "            self.billing_time[resource] += finish_time[task]\n",
        "\n",
        "        self.makespan = max(finish_time.values())\n",
        "        self.processing_time = copy.deepcopy(processing_time)\n",
        "\n",
        "\n",
        "    def calculate_cost(self, tasks_dict, resources_dict, dag_dict):\n",
        "        cost = dict()\n",
        "\n",
        "        for (task, resource) in self.workflow:\n",
        "            c1 = self.processing_time[task] * resources_dict[resource].price\n",
        "            c2 = (sum([x.size for x in tasks_dict[task].input_files])/(1024*1024*1024.0) + sum([x.size for x in tasks_dict[task].output_files])/(1024*1024*1024.0)) * resources_dict[resource].price\n",
        "            cost[task] = c1 + c2\n",
        "\n",
        "        self.cost = copy.deepcopy(cost)\n",
        "        self.total_cost = sum(cost.values())\n",
        "\n",
        "\n",
        "    def calculate_degree_of_imbalance(self, resources_dict):\n",
        "        degree_of_imbalance = dict()\n",
        "\n",
        "        for resource in resources_dict:\n",
        "            degree_of_imbalance[resource] = 0\n",
        "\n",
        "        for (task, resource) in self.workflow:\n",
        "            degree_of_imbalance[resource] = degree_of_imbalance[resource] + self.processing_time[task]\n",
        "\n",
        "        dib_min = min(list(degree_of_imbalance.values()))\n",
        "        dib_max = max(list(degree_of_imbalance.values()))\n",
        "        dib_avg = statistics.mean(degree_of_imbalance.values())\n",
        "\n",
        "        self.degree_of_imbalance = (dib_max-dib_min)/dib_avg\n",
        "\n",
        "\n",
        "    def calculate_reliability(self):\n",
        "        reliability = dict()\n",
        "        for task in self.processing_time:\n",
        "            reliability[task] = 1 - float(np.exp(-np.power(self.processing_time[task]/n, b)))\n",
        "\n",
        "        rel = 1.0\n",
        "        for task in reliability:\n",
        "            rel = rel * reliability[task]\n",
        "\n",
        "        self.rel_inverse = rel\n",
        "\n",
        "\n",
        "    def calculate_energy(self, tasks_dict, resources_dict, dag_dict):\n",
        "        execution_energy = 0\n",
        "        transfer_energy = 0\n",
        "\n",
        "        for (task, resource) in self.workflow:\n",
        "            execution_energy += (resources_dict[resource].id + 1) * 1 * self.processing_time[task]\n",
        "            \n",
        "            for predecessor in tasks_dict[task].predecessor_tasks:\n",
        "                if resource != self.task_to_resource_dict[predecessor]:\n",
        "                    transfer_energy += (resources_dict[self.task_to_resource_dict[predecessor]].id + 1) * (0.4 * 0.4 * 0.4) * dag_dict[predecessor][task]/(1024.0*1024*1024)\n",
        "        \n",
        "        self.energy = execution_energy + transfer_energy\n",
        "\n",
        "\n",
        "    def schedule(self, id, tasks_dict, resources_dict, dag_dict):\n",
        "        self.id = id\n",
        "        self.calculate_makespan(tasks_dict, resources_dict, dag_dict)\n",
        "        self.calculate_cost(tasks_dict, resources_dict, dag_dict)\n",
        "        self.calculate_degree_of_imbalance(resources_dict)\n",
        "        self.calculate_reliability()\n",
        "        self.calculate_energy(tasks_dict, resources_dict, dag_dict)\n",
        "\n",
        "    def get_sorted_workflow(self):\n",
        "        t = copy.deepcopy(self.workflow)\n",
        "        t.sort(key = lambda x: x[0])\n",
        "        return [x[1] for x in t]\n",
        "\n",
        "    def print(self, resources_dict):\n",
        "        print(\"ID: {}\\nMakespan: {}\\nCost: {}\\nReliability: {}\\nDegree of Imbalance: {}\".format(self.id, self.makespan, self.total_cost, self.rel_inverse, self.degree_of_imbalance))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "D_t3HnfF4h2q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#This cells return B-Rank\n",
        "\n",
        "b_rank = dict()\n",
        "\n",
        "def get_b_rank(tasks_dict, task):\n",
        "    #recursive function to calculate b_rank\n",
        "    rank = 0\n",
        "    if len(tasks_dict[task].successor_tasks) > 0:\n",
        "        rank = 1\n",
        "    for successor in tasks_dict[task].successor_tasks:\n",
        "        rank = max(rank, get_b_rank(tasks_dict, successor)+1)\n",
        "    b_rank[task] = rank\n",
        "    return rank\n",
        "\n",
        "def calculate_b_rank(tasks_dict):\n",
        "    #Driver function to get B-rank\n",
        "    for task in tasks_dict:\n",
        "        b_rank[task] = -1\n",
        "\n",
        "    for task in tasks_dict:\n",
        "        if b_rank[task] == -1:\n",
        "            get_b_rank(tasks_dict, task)\n",
        "\n",
        "    rank_list = list()\n",
        "\n",
        "    for (x, y) in sorted(b_rank.items(), key = lambda kv:(kv[1], kv[0])):\n",
        "        rank_list.append(x)\n",
        "\n",
        "    return rank_list[::-1]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "8BXy_6t44h2w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Returns crowding distance sorted workflows\n",
        "\n",
        "def sort_by_objective(schedule_list, objective):\n",
        "    distance_dict = dict()\n",
        "    values = list()\n",
        "\n",
        "    if objective == 'makespan':\n",
        "        schedule_list.sort(key = lambda x: x.makespan)\n",
        "        values = [x.makespan for x in schedule_list]\n",
        "    elif objective == 'cost':\n",
        "        schedule_list.sort(key = lambda x: x.total_cost)\n",
        "        values = [x.total_cost for x in schedule_list]\n",
        "    elif objective == 'degree_of_imbalance':\n",
        "        schedule_list.sort(key = lambda x: x.degree_of_imbalance)\n",
        "        values = [x.degree_of_imbalance for x in schedule_list]\n",
        "    elif objective == 'reliability':\n",
        "        schedule_list.sort(key = lambda x: x.rel_inverse)\n",
        "        values = [x.rel_inverse for x in schedule_list]\n",
        "\n",
        "    first_item = schedule_list[0]\n",
        "    last_item = schedule_list[-1]\n",
        "\n",
        "    first_value = values[0]\n",
        "    last_value = values[-1]\n",
        "\n",
        "    i = 1\n",
        "    distance_dict = dict()\n",
        "\n",
        "    while i < len(schedule_list)-1:\n",
        "        if last_value-first_value != 0:\n",
        "            dist = math.fabs((values[i+1] - values[i-1]) / (last_value - first_value))\n",
        "        else:\n",
        "            dist = 0\n",
        "\n",
        "        distance_dict[schedule_list[i].id] =  dist\n",
        "        i = i + 1\n",
        "\n",
        "    return distance_dict, first_item, last_item\n",
        "\n",
        "def crowding_distance_sort(schedule_list, K):\n",
        "    makespan_distance_dict, first_item_makespan, last_item_makespan = sort_by_objective(schedule_list, 'makespan')\n",
        "    cost_distance_dict, first_item_cost, last_item_cost = sort_by_objective(schedule_list, 'cost')\n",
        "    # degree_of_imbalance_distance_dict, first_item_degree_of_imbalance, last_item_degree_of_imbalance = sort_by_objective(schedule_list, 'degree_of_imbalance')\n",
        "    reliability_distance_dict, first_item_rel, last_item_rel = sort_by_objective(schedule_list, 'reliability')\n",
        "\n",
        "    crowding_distance = list()\n",
        "\n",
        "    makespan_dis_id_list = list(makespan_distance_dict.keys())\n",
        "    cost_dis_id_list = list(cost_distance_dict.keys())\n",
        "    # degree_of_imbalance_id_list = list(degree_of_imbalance_distance_dict.keys())\n",
        "    reliability_dis_id_list = list(reliability_distance_dict.keys())\n",
        "\n",
        "    for id in makespan_dis_id_list:\n",
        "        if id in cost_dis_id_list and id in reliability_dis_id_list:\n",
        "            distance = makespan_distance_dict[id] + cost_distance_dict[id] + reliability_distance_dict[id]\n",
        "            crowding_distance.append((id, distance))\n",
        "\n",
        "    sorted_crowding_distance = sorted(crowding_distance, key=lambda d: d[1], reverse=True)\n",
        "\n",
        "    prior_list = []\n",
        "    result = list()\n",
        "\n",
        "    for item in [first_item_makespan, last_item_makespan, first_item_cost, last_item_cost, first_item_rel, last_item_rel]:\n",
        "        exit = False\n",
        "\n",
        "        for i in prior_list:\n",
        "            if first_item_makespan.id == i.id:\n",
        "                exit = True\n",
        "                break\n",
        "\n",
        "        if exit is False:\n",
        "            prior_list.append(item)\n",
        "\n",
        "    if K >= len(prior_list):\n",
        "        result.extend(prior_list)\n",
        "        left_num = K - len(prior_list)\n",
        "        j = 0\n",
        "        while j < left_num and j < len(sorted_crowding_distance):\n",
        "            individual_id = sorted_crowding_distance[j][0]\n",
        "\n",
        "            for s in schedule_list:\n",
        "                if s.id == individual_id:\n",
        "                    result.append(s)\n",
        "                    break\n",
        "            j = j + 1\n",
        "    else:\n",
        "        result = prior_list[:K]\n",
        "    return result\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "trusted": true,
        "id": "YAto4OLm4h23",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Returns pareto solutions\n",
        "\n",
        "def get_pareto_result(schedules):\n",
        "    pareto_list = list()\n",
        "\n",
        "    if schedules is not None:\n",
        "        for s1 in schedules:\n",
        "            defeat = False\n",
        "\n",
        "            for s2 in schedules:\n",
        "                if s1.id != s2.id:\n",
        "                    if (s2.makespan <= s1.makespan and s2.total_cost < s1.total_cost and s2.rel_inverse < s1.rel_inverse) or (s2.total_cost <= s1.total_cost and s2.makespan < s1.makespan and s2.rel_inverse < s1.rel_inverse) or (s2.rel_inverse <= s1.rel_inverse and s2.total_cost < s1.total_cost and s2.makespan < s1.makespan):\n",
        "                        defeat = True\n",
        "                        break\n",
        "\n",
        "            if defeat is False:\n",
        "                pareto_list.append(s1)\n",
        "\n",
        "    return pareto_list\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "59OQTQ274h27",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def init_resources(total_resources):\n",
        "    instance_per_resource = int(total_resources/len(RESOURCES))\n",
        "\n",
        "    resources_dict = dict()\n",
        "    id = 0\n",
        "\n",
        "    for resource in RESOURCES:\n",
        "        for i in range(instance_per_resource):\n",
        "            resources_dict[id] = Resource(id = id, type = resource['type'], cu = resource['cu'], price = resource['price'])\n",
        "            id = id + 1\n",
        "\n",
        "    return resources_dict\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "b2vFA5GM4h2_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_weight(successor_input_files, task_output_files):\n",
        "    weight = 0\n",
        "    for input_file in successor_input_files:\n",
        "        for output_file in task_output_files:\n",
        "            if input_file.name == output_file.name:\n",
        "                weight = weight + max(input_file.size, output_file.size)\n",
        "\n",
        "    return weight\n",
        "\n",
        "def init_task_dag(tasks_dict):\n",
        "    dag_dict = dict()\n",
        "\n",
        "    for task in tasks_dict:\n",
        "        temp = dict()\n",
        "        for successor in tasks_dict[task].successor_tasks:\n",
        "            temp[successor] = get_weight(tasks_dict[successor].input_files, tasks_dict[task].output_files)\n",
        "        dag_dict[task] = temp\n",
        "\n",
        "    return dag_dict\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Bbt1UIbP4h3H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def init_tasks(filename):\n",
        "    root = ET.parse(filename).getroot()\n",
        "    tasks_dict = dict()\n",
        "\n",
        "    for task in root.findall('./{http://pegasus.isi.edu/schema/DAX}job'):\n",
        "        temp = Task(id = task.attrib['id'], runtime = float(task.attrib['runtime']))\n",
        "\n",
        "        for file in task:\n",
        "            if file.attrib['link'] == 'input':\n",
        "                temp.add_input_file(File(name = file.attrib['file'], size = int(file.attrib['size'])))\n",
        "            else:\n",
        "                temp.add_output_file(File(name = file.attrib['file'], size = int(file.attrib['size'])))\n",
        "\n",
        "        tasks_dict[temp.id] = temp\n",
        "\n",
        "    for child in root.findall('./{http://pegasus.isi.edu/schema/DAX}child'):\n",
        "        for parent in child:\n",
        "            tasks_dict[child.attrib['ref']].add_predecessor_task(parent.attrib['ref'])\n",
        "            tasks_dict[parent.attrib['ref']].add_successor_task(child.attrib['ref'])\n",
        "\n",
        "    return tasks_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "O2H1EPbk4h3M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def moheft(tasks_dict, resources_dict, dag_dict, K):\n",
        "    b_rank = calculate_b_rank(tasks_dict)\n",
        "\n",
        "    schedules = list()\n",
        "\n",
        "    for i in range(K):\n",
        "        schedules.append(Workflow())\n",
        "\n",
        "    for i in range(len(b_rank)):\n",
        "        print(\"----Running iteration {}----\".format(i+1))\n",
        "        temp_list = list()\n",
        "\n",
        "        if len(schedules) > 0:\n",
        "            for s in schedules:\n",
        "                for resource in resources_dict:\n",
        "                    temp = copy.deepcopy(s)\n",
        "                    temp.add_to_workflow(task = b_rank[i], resource = resource)\n",
        "                    temp_list.append(temp)\n",
        "\n",
        "        else:\n",
        "            for resource in resources_dict:\n",
        "                temp = copy.deepcopy(s)\n",
        "                temp.add_to_workflow(task = b_rank[i], resource = resource)\n",
        "                temp_list.append(temp)\n",
        "\n",
        "        counter = 0\n",
        "        for s in temp_list:\n",
        "            s.schedule(counter, tasks_dict, resources_dict, dag_dict)\n",
        "            counter = counter + 1\n",
        "        schedules = crowding_distance_sort(temp_list, K)\n",
        "\n",
        "    return get_pareto_result(schedules)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "np_vJPo-4h3Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_dist(s1, s2):\n",
        "    # dist = float(math.sqrt(math.pow((s1.makespan-s2.makespan),2) + math.pow((s1.total_cost-s2.total_cost),2) + math.pow((s1.rel_inverse-s2.rel_inverse),2) + math.pow((s1.degree_of_imbalance-s2.degree_of_imbalance),2) + math.pow((s1.energy - s2.energy), 2)))\n",
        "    dist = float(math.sqrt(math.pow((s1.makespan-s2.makespan),2) + math.pow((s1.total_cost-s2.total_cost),2) + math.pow((s1.rel_inverse-s2.rel_inverse),2)))\n",
        "    return dist\n",
        "\n",
        "def pair_solutions(S1, S2):\n",
        "    pairs = list()\n",
        "\n",
        "    if len(S1) <= len(S2):\n",
        "        for s1 in S1:\n",
        "            min_dist = -1\n",
        "            id = 0\n",
        "            for s2 in S2:\n",
        "                dist = get_dist(s1, s2)\n",
        "                if min_dist == -1 or dist < min_dist:\n",
        "                    min_dist = dist\n",
        "                    id = s2\n",
        "\n",
        "            pairs.append((s1, id))\n",
        "    else:\n",
        "        for s2 in S2:\n",
        "            min_dist = -1\n",
        "            id = 0\n",
        "            for s1 in S1:\n",
        "                dist = get_dist(s1, s2)\n",
        "                if min_dist == -1 or dist < min_dist:\n",
        "                    min_dist = dist\n",
        "                    id = s1\n",
        "\n",
        "            pairs.append((id, s2))\n",
        "\n",
        "    return pairs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "1ig8VTgW4h3U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot(S, filename, type, K):\n",
        "    makespan_x = list()\n",
        "    makespan_y = list()\n",
        "\n",
        "    cost_x = list()\n",
        "    cost_y = list()\n",
        "\n",
        "    rel_inverse_x = list()\n",
        "    rel_inverse_y = list()\n",
        "\n",
        "    deg_of_imb_x = list()\n",
        "    deg_of_imb_y = list()\n",
        "\n",
        "    energy_x = list()\n",
        "    energy_y = list()\n",
        "\n",
        "    S = sorted(S, key = lambda x: x.id)\n",
        "\n",
        "\n",
        "    for i in range(len(S)):\n",
        "        makespan_x.append(i)\n",
        "        makespan_y.append(S[i].makespan)\n",
        "        cost_x.append(i)\n",
        "        cost_y.append(S[i].total_cost)\n",
        "        rel_inverse_x.append(i)\n",
        "        rel_inverse_y.append(S[i].rel_inverse)\n",
        "        deg_of_imb_x.append(i)\n",
        "        deg_of_imb_y.append(S[i].degree_of_imbalance)\n",
        "        energy_x.append(i)\n",
        "        energy_y.append(S[i].energy)\n",
        "\n",
        "\n",
        "    plt.plot(makespan_x, makespan_y)\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "    plt.plot(cost_x, cost_y)\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "    plt.plot(rel_inverse_x, rel_inverse_y)\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "    plt.plot(deg_of_imb_x, deg_of_imb_y)\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "    plt.plot(energy_x, energy_y)\n",
        "    plt.show()\n",
        "    plt.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "CG6eGah44h3a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def round_result(result):\n",
        "    return_result = list()\n",
        "    for a in result:\n",
        "        return_result.append([round(x) for x in a])\n",
        "\n",
        "    return return_result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "HZJYIsae4h3d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def validate_solution(filename, result, tasks_dict, resources_dict, dag_dict, parent_solution, K):\n",
        "    print(result)\n",
        "    rounded_result = round_result(result)\n",
        "\n",
        "    wf_list = list()\n",
        "\n",
        "    BASE = 'ID000'\n",
        "    id_list = list()\n",
        "\n",
        "    for i in range(len(result[0])):\n",
        "        if i < 10:\n",
        "            id_list.append(BASE+'0'+str(i))\n",
        "        else:\n",
        "            id_list.append(BASE+str(i))\n",
        "\n",
        "    for r in rounded_result:\n",
        "        wf_list.append(Workflow())\n",
        "\n",
        "    for i in range(len(wf_list)):\n",
        "        for j in range(len(rounded_result[i])):\n",
        "            if rounded_result[i][j] > max(resources_dict.keys()):\n",
        "                wf_list[i].add_to_workflow(id_list[j], max(resources_dict.keys()))\n",
        "            elif rounded_result[i][j] < 0:\n",
        "                wf_list[i].add_to_workflow(id_list[j], 0)\n",
        "            else:\n",
        "                wf_list[i].add_to_workflow(id_list[j], rounded_result[i][j])\n",
        "\n",
        "    for k in range(len(parent_solution)):\n",
        "        wf_list.append(Workflow())\n",
        "\n",
        "    for j in range(len(parent_solution)):\n",
        "        for (task, resource) in parent_solution[j].workflow:\n",
        "            wf_list[i+j+1].add_to_workflow(task, resource)\n",
        "\n",
        "    for i in range(len(wf_list)):\n",
        "        wf_list[i].schedule(i, tasks_dict, resources_dict, dag_dict)\n",
        "\n",
        "    wf_list = crowding_distance_sort(wf_list, K)\n",
        "\n",
        "    return get_pareto_result(wf_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "tKNEc1wm4h3g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(t1, t2):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(units=2*len(t1[0]), activation='linear', input_dim=len(t1[0])))\n",
        "    model.add(Dense(len(t1[0]),activation='linear'))\n",
        "    model.compile(optimizer = 'adam', loss='mae', metrics=['accuracy'])\n",
        "    history = model.fit(t1, t2, epochs = 10000, batch_size = 10, verbose=0)\n",
        "    result = model.predict(t2)\n",
        "    return result.tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "PrYSQ4sF4h3n",
        "colab_type": "code",
        "outputId": "eafc043a-9765-4254-b8db-297bb77f48ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print(\"----Generating Resources Dict1----\")\n",
        "resources_dict = init_resources(total_resources)\n",
        "\n",
        "print(\"----Generating Tasks Dict----\")\n",
        "tasks_dict = init_tasks(filename = filename)\n",
        "\n",
        "print(\"----Generating Dag Dict----\")\n",
        "dag_dict = init_task_dag(tasks_dict)\n",
        "\n",
        "print(\"----Running Moheft1----\")\n",
        "S1 = moheft(tasks_dict, resources_dict, dag_dict, K)\n",
        "print(\"----Running Moheft2----\")\n",
        "S2 = moheft(tasks_dict, resources_dict, dag_dict, K+100)\n",
        "print(\"----Running Moheft3----\")\n",
        "S3 = moheft(tasks_dict, resources_dict, dag_dict, K+200)\n",
        "\n",
        "pairs = pair_solutions(S1, S2)\n",
        "\n",
        "t1 = list()\n",
        "t2 = list()\n",
        "\n",
        "for (x, y) in pairs:\n",
        "    t1.append(x.get_sorted_workflow())\n",
        "    t2.append(y.get_sorted_workflow())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----Generating Resources Dict1----\n",
            "----Generating Tasks Dict----\n",
            "----Generating Dag Dict----\n",
            "----Running Moheft1----\n",
            "----Running iteration 1----\n",
            "----Running iteration 2----\n",
            "----Running iteration 3----\n",
            "----Running iteration 4----\n",
            "----Running iteration 5----\n",
            "----Running iteration 6----\n",
            "----Running iteration 7----\n",
            "----Running iteration 8----\n",
            "----Running iteration 9----\n",
            "----Running iteration 10----\n",
            "----Running iteration 11----\n",
            "----Running iteration 12----\n",
            "----Running iteration 13----\n",
            "----Running iteration 14----\n",
            "----Running iteration 15----\n",
            "----Running iteration 16----\n",
            "----Running iteration 17----\n",
            "----Running iteration 18----\n",
            "----Running iteration 19----\n",
            "----Running iteration 20----\n",
            "----Running iteration 21----\n",
            "----Running iteration 22----\n",
            "----Running iteration 23----\n",
            "----Running iteration 24----\n",
            "----Running iteration 25----\n",
            "----Running iteration 26----\n",
            "----Running iteration 27----\n",
            "----Running iteration 28----\n",
            "----Running iteration 29----\n",
            "----Running iteration 30----\n",
            "----Running iteration 31----\n",
            "----Running iteration 32----\n",
            "----Running iteration 33----\n",
            "----Running iteration 34----\n",
            "----Running iteration 35----\n",
            "----Running iteration 36----\n",
            "----Running iteration 37----\n",
            "----Running iteration 38----\n",
            "----Running iteration 39----\n",
            "----Running iteration 40----\n",
            "----Running iteration 41----\n",
            "----Running iteration 42----\n",
            "----Running iteration 43----\n",
            "----Running iteration 44----\n",
            "----Running iteration 45----\n",
            "----Running iteration 46----\n",
            "----Running iteration 47----\n",
            "----Running iteration 48----\n",
            "----Running iteration 49----\n",
            "----Running iteration 50----\n",
            "----Running iteration 51----\n",
            "----Running iteration 52----\n",
            "----Running iteration 53----\n",
            "----Running iteration 54----\n",
            "----Running iteration 55----\n",
            "----Running iteration 56----\n",
            "----Running iteration 57----\n",
            "----Running iteration 58----\n",
            "----Running iteration 59----\n",
            "----Running iteration 60----\n",
            "----Running iteration 61----\n",
            "----Running iteration 62----\n",
            "----Running iteration 63----\n",
            "----Running iteration 64----\n",
            "----Running iteration 65----\n",
            "----Running iteration 66----\n",
            "----Running iteration 67----\n",
            "----Running iteration 68----\n",
            "----Running iteration 69----\n",
            "----Running iteration 70----\n",
            "----Running iteration 71----\n",
            "----Running iteration 72----\n",
            "----Running iteration 73----\n",
            "----Running iteration 74----\n",
            "----Running iteration 75----\n",
            "----Running iteration 76----\n",
            "----Running iteration 77----\n",
            "----Running iteration 78----\n",
            "----Running iteration 79----\n",
            "----Running iteration 80----\n",
            "----Running iteration 81----\n",
            "----Running iteration 82----\n",
            "----Running iteration 83----\n",
            "----Running iteration 84----\n",
            "----Running iteration 85----\n",
            "----Running iteration 86----\n",
            "----Running iteration 87----\n",
            "----Running iteration 88----\n",
            "----Running iteration 89----\n",
            "----Running iteration 90----\n",
            "----Running iteration 91----\n",
            "----Running iteration 92----\n",
            "----Running iteration 93----\n",
            "----Running iteration 94----\n",
            "----Running iteration 95----\n",
            "----Running iteration 96----\n",
            "----Running iteration 97----\n",
            "----Running iteration 98----\n",
            "----Running iteration 99----\n",
            "----Running iteration 100----\n",
            "----Running Moheft2----\n",
            "----Running iteration 1----\n",
            "----Running iteration 2----\n",
            "----Running iteration 3----\n",
            "----Running iteration 4----\n",
            "----Running iteration 5----\n",
            "----Running iteration 6----\n",
            "----Running iteration 7----\n",
            "----Running iteration 8----\n",
            "----Running iteration 9----\n",
            "----Running iteration 10----\n",
            "----Running iteration 11----\n",
            "----Running iteration 12----\n",
            "----Running iteration 13----\n",
            "----Running iteration 14----\n",
            "----Running iteration 15----\n",
            "----Running iteration 16----\n",
            "----Running iteration 17----\n",
            "----Running iteration 18----\n",
            "----Running iteration 19----\n",
            "----Running iteration 20----\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSk6S1nuJFl3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result = train_model(t1, t2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqU3qL9uK0RQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "S4 = validate_solution(filename, result, tasks_dict, resources_dict, dag_dict, S2, 3*K)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYL_febML_gV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot(S1, filename, 'input_training', K)\n",
        "plot(S2, filename, 'output_training', K+100)\n",
        "plot(S3, filename, 'moheft_output', K+200)\n",
        "plot(S4, filename, 'output_validation', K+200)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9LZbTf-2ihM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calculate_hv(workflows):\n",
        "    reference_point = [1.1, 1.1, 1.1, 1.1, 1.1] \n",
        "    hv = HyperVolume(reference_point)\n",
        "    max_makespan = 0\n",
        "    max_cost = 0\n",
        "    max_dib = 0\n",
        "    max_rel_inv = 0\n",
        "    max_energy = 0\n",
        "    fronts = list()\n",
        "\n",
        "    for workflow in workflows:\n",
        "        fronts.append(list())\n",
        "        max_makespan = max(max_makespan, max([x.makespan for x in workflow]))\n",
        "        max_cost = max(max_cost, max([x.total_cost for x in workflow]))\n",
        "        max_dib = max(max_dib, max([x.degree_of_imbalance for x in workflow]))\n",
        "        max_rel_inv = max(max_rel_inv, max([x.rel_inverse for x in workflow]))\n",
        "        max_energy = max(max_energy, max([x.energy for x in workflow]))\n",
        "    \n",
        "    \n",
        "    \n",
        "\n",
        "    for i in range(len(workflows)):\n",
        "        for s in workflows[i]:\n",
        "            fronts[i].append([s.makespan/max_makespan, s.total_cost/max_cost, s.degree_of_imbalance/max_dib, s.rel_inverse/1, s.energy/max_energy])\n",
        "\n",
        "    volumes = list()\n",
        "\n",
        "    for front in fronts:\n",
        "        volumes.append(hv.compute(front))\n",
        "\n",
        "    return volumes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VlnxGz9UGI2x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "volumes = calculate_hv([S1, S2, S3, S4])\n",
        "print(volumes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HipB9XqGR-J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "volumes_x = list()\n",
        "volumes_y = list()\n",
        "for i in range(len(volumes)):\n",
        "  volumes_x.append(i)\n",
        "  volumes_y.append(volumes[i])\n",
        "\n",
        "plt.plot(volumes_x, volumes_y)\n",
        "plt.show()\n",
        "plt.close()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}